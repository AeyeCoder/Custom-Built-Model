{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c55dc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x,y),(x_test,y_test)=tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train=x[:55000,:]\n",
    "y_train=y[:55000]\n",
    "x_val=x[55000:,:]\n",
    "y_val=y[55000:]\n",
    "x_train,x_test,x_val=x_train/255.0,x_test/255.0,x_val/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde0ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Double_Boundary_HuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,delta1=1,delta2=1.5,**kwargs):\n",
    "        self.delta1=delta1\n",
    "        self.delta2=delta2\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# This commented one is for regression and the uncommented is for classfication.\n",
    "\n",
    "#    def call(self,y_true,y_pred):\n",
    "#        error=tf.abs(y_pred-y_true)\n",
    "#        small_error=(error**2)/2\n",
    "#        medium_error=(error*(error**(1/2)))/2\n",
    "#        large_error=(error*self.delta2)-(self.delta1**2)/2\n",
    "#        return tf.where(error<self.delta1,small_error,tf.where(error<self.delta2,medium_error,large_error))\n",
    "    \n",
    "    \n",
    "\n",
    "    def call(self,y_true,y_pred):\n",
    "        y_true=tf.one_hot(tf.cast(y_true,tf.int32),depth=tf.shape(y_pred)[-1])\n",
    "        error=tf.abs(y_pred-y_true)\n",
    "        small_error=(error**2)/2\n",
    "        error=tf.clip_by_value(error,0,5)\n",
    "        medium_error=(error*(error**(1/2)))/2\n",
    "        large_error=(error*self.delta2)-(self.delta1**2)/2\n",
    "        return tf.reduce_mean(tf.where(error<self.delta1,small_error,tf.where(error<self.delta2,medium_error,large_error)))\n",
    "    def get_config(self):\n",
    "        base_config=super().get_config()\n",
    "        return {**base_config,\"delta1\":self.delta1,\"delta2\":self.delta2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071dd614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class he_normal(tf.keras.initializers.Initializer):\n",
    "    def __call__(self,shape,dtype=None):\n",
    "        n_inputs=shape[-2]\n",
    "        stddev=tf.sqrt(2/tf.cast(n_inputs,tf.float32))\n",
    "        return tf.random.normal(shape,stddev=stddev,dtype=dtype)\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "    \n",
    "class l2_reg(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self,penalty=0.01):\n",
    "        self.penalty=penalty\n",
    "    def __call__(self,data):\n",
    "        return (self.penalty)*(tf.reduce_sum((data**2)))\n",
    "    def get_config(self):\n",
    "        return {\"l2\":self.penalty}\n",
    "def nonneg(x):\n",
    "        return tf.keras.activations.relu(x)\n",
    "def mish(x):\n",
    "        return x*tf.math.tanh(tf.math.softplus(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c315d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self,delta1=1,delta2=2,name=\"HuberMetric\",**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.delta1=delta1\n",
    "        self.delta2=delta2\n",
    "        self.total=self.add_weight(name=\"total\",initializer=\"zeros\")\n",
    "        self.count=self.add_weight(name=\"count\",initializer=\"zeros\")\n",
    "    def update_state(self,y_true,y_pred):\n",
    "        y_true=tf.cast(y_true,tf.int32)\n",
    "        y_true=tf.one_hot(y_true,depth=tf.shape(y_pred)[-1])\n",
    "        y_true=tf.cast(y_true,tf.float32)\n",
    "        error=tf.abs(y_true-y_pred)\n",
    "\n",
    "        is_small=tf.less(error,self.delta1)\n",
    "        small_error=(error**2)/2\n",
    "\n",
    "        is_mid=tf.logical_and(tf.greater_equal(error,self.delta1),tf.less(error,self.delta2))\n",
    "        error=tf.clip_by_value(error,1e-7,1e3)\n",
    "        mid_error=((error**2)*tf.sqrt(error))/2\n",
    "\n",
    "        large_error=(error*self.delta1)-((1/2)*(self.delta2)**2)\n",
    "\n",
    "        huber_val=tf.where(is_small,small_error,tf.where(is_mid,mid_error,large_error))\n",
    "        self.total.assign_add(tf.reduce_sum(huber_val))\n",
    "        self.count.assign_add(tf.cast(tf.size(huber_val),tf.float32))\n",
    "    def result(self):\n",
    "        return self.total/self.count\n",
    "    def reset(self):\n",
    "        self.total.assign(0)\n",
    "        self.count.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03777c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,units,activation=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units=units\n",
    "        self.activation=tf.keras.activations.get(activation)\n",
    "    def build(self,shape):\n",
    "        n_inputs=shape[-1]\n",
    "        self.weight=self.add_weight(\n",
    "            shape=(n_inputs,self.units),\n",
    "            initializer=\"he_normal\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self.bias=self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True\n",
    "        )\n",
    "    def call(self,inputs):\n",
    "        z=tf.matmul(inputs,self.weight)+self.bias\n",
    "        return self.activation(z) if self.activation else z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e867698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,units,activation=\"relu\",**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1=tf.keras.layers.Dense(units,activation=activation)\n",
    "        self.hidden2=tf.keras.layers.Dense(units)\n",
    "\n",
    "    def call(self,inputs):\n",
    "        z=self.hidden1(inputs)\n",
    "        z=self.hidden2(z)\n",
    "        return z\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config=super().get_config()\n",
    "        return {**base_config,\"activation\":self.activation,\"units\":self.units}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48871a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self,num_classes=10,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.flatten=tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.hidden1=MyDenseLayer(256,activation=mish)\n",
    "\n",
    "        self.resblock1=ResidualBlock(256)\n",
    "        self.resblock2=ResidualBlock(256)\n",
    "\n",
    "        self.hidden2=MyDenseLayer(64,activation=nonneg)\n",
    "        self.hidden3=MyDenseLayer(32,activation=mish)\n",
    "        \n",
    "        self.classifier=MyDenseLayer(num_classes,activation=\"softmax\")\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        x=self.flatten(inputs)\n",
    "        x=self.hidden1(x)\n",
    "        x=self.resblock1(x)+x\n",
    "        x=self.resblock2(x)+x\n",
    "        x=self.hidden2(x)\n",
    "        x=self.hidden3(x)\n",
    "        return self.classifier(x)\n",
    "    def get_config(self):\n",
    "        base=super().get_config()\n",
    "        return {\"num_classes\":10,**base}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "031507b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train Accuracy:  0.82036364\n",
      "Val_Score:  0.8594\n",
      "Epoch 2:\n",
      "Train Accuracy:  0.8609273\n",
      "Val_Score:  0.8652\n",
      "Epoch 3:\n",
      "Train Accuracy:  0.87665457\n",
      "Val_Score:  0.8688\n",
      "Epoch 4:\n",
      "Train Accuracy:  0.88485456\n",
      "Val_Score:  0.8712\n",
      "Epoch 5:\n",
      "Train Accuracy:  0.8924\n",
      "Val_Score:  0.877\n"
     ]
    }
   ],
   "source": [
    "model=MyModel()\n",
    "train_metric=HuberMetric()\n",
    "val_metric=HuberMetric()\n",
    "optimizer=tf.keras.optimizers.Adam()\n",
    "loss_func=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "initializer=he_normal()\n",
    "train_acc=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "ds_train=tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(32)\n",
    "ds_val=tf.data.Dataset.from_tensor_slices((x_val,y_val)).batch(32)\n",
    "\n",
    "n_epochs=5\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    for x_batch,y_batch in ds_train:\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits=model(x_batch,training=True)\n",
    "            loss=loss_func(y_batch,logits)\n",
    "        grads=tape.gradient(loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "        train_acc.update_state(y_batch,logits)\n",
    "    print(\"Train Accuracy: \",train_acc.result().numpy())\n",
    "    train_acc.reset_state()\n",
    "    for x_batch,y_batch in ds_val:\n",
    "        val_logits=model(x_batch,training=False)\n",
    "        val_acc.update_state(y_batch,val_logits)\n",
    "    print(\"Val_Score: \",val_acc.result().numpy())\n",
    "    val_acc.reset_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
